<!DOCTYPE html><!--JU7X53FC3NyGNUqwbDOVC--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/d030d367e034049b.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-6e1697fef140febb.js"/><script src="/_next/static/chunks/72d9b9fe-881c608dfd3d6075.js" async=""></script><script src="/_next/static/chunks/59-ac558f0723878dde.js" async=""></script><script src="/_next/static/chunks/main-app-52c49b64f0218f99.js" async=""></script><script src="/_next/static/chunks/102969c4-60ccef36263800a0.js" async=""></script><script src="/_next/static/chunks/64d1c0c4-a3ef1c2074d5cee5.js" async=""></script><script src="/_next/static/chunks/205-e96f68d7203b15f6.js" async=""></script><script src="/_next/static/chunks/3-63e812f17dc5f3c8.js" async=""></script><script src="/_next/static/chunks/app/posts/%5Bslug%5D/page-149ed8916e948834.js" async=""></script><script src="/_next/static/chunks/app/layout-6e1c24235b3dba30.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-077BT1Q7PJ" as="script"/><title>When LLM Reasoning Becomes the Pattern - Meta-Classification Failure Modes | Augustin Chan</title><meta name="description" content="Hard constraints beat soft self-regulation when an LLM&#x27;s reasoning converges to a template."/><link rel="author" href="https://augustinchan.dev"/><meta name="author" content="Augustin Chan"/><meta name="keywords" content="AI,Machine Learning,Web3,Software Engineering,React,Next.js,TypeScript,Blog"/><meta name="creator" content="Augustin Chan"/><meta name="publisher" content="Augustin Chan"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://augustinchan.dev/posts/2025-09-27-llm-reasoning-pattern-classification-failure-modes"/><meta property="og:title" content="When LLM Reasoning Becomes the Pattern - Meta-Classification Failure Modes"/><meta property="og:description" content="Hard constraints beat soft self-regulation when an LLM&#x27;s reasoning converges to a template."/><meta property="og:url" content="https://augustinchan.dev/posts/2025-09-27-llm-reasoning-pattern-classification-failure-modes"/><meta property="og:site_name" content="Augustin Chan"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://augustinchan.dev/img/Xrn0Id68_400x400.jpg"/><meta property="og:image:width" content="400"/><meta property="og:image:height" content="400"/><meta property="og:image:alt" content="When LLM Reasoning Becomes the Pattern - Meta-Classification Failure Modes"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2025-09-27T00:00:00.000Z"/><meta property="article:author" content="Augustin Chan"/><meta property="article:section" content="Technology"/><meta property="article:tag" content="AI"/><meta property="article:tag" content="Machine Learning"/><meta property="article:tag" content="Web3"/><meta property="article:tag" content="Software Engineering"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@augchan42"/><meta name="twitter:title" content="When LLM Reasoning Becomes the Pattern - Meta-Classification Failure Modes"/><meta name="twitter:description" content="Hard constraints beat soft self-regulation when an LLM&#x27;s reasoning converges to a template."/><meta name="twitter:image" content="https://augustinchan.dev/img/Xrn0Id68_400x400.jpg"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div hidden=""><!--$--><!--/$--></div><div style="max-width:1000px;margin:0 auto;padding:2rem"><header style="border-bottom:2px solid #333;padding-bottom:1rem;margin-bottom:2rem"><nav style="display:flex;justify-content:space-between;align-items:center;flex-wrap:wrap;gap:1rem"><div><a style="font-size:1.6rem;font-weight:bold;text-decoration:none;color:#333" href="/">Augustin Chan</a><div style="margin-top:0.5rem">Building systems that reason</div></div><div style="display:flex;gap:1.5rem;flex-wrap:wrap"><a style="text-decoration:none;color:#666" href="/">Home</a><a style="text-decoration:none;color:#666" href="/about">About</a><a style="text-decoration:none;color:#666" href="/blog">Blog</a><a href="https://8bitoracle.ai" target="_blank" rel="noopener noreferrer" style="text-decoration:none;color:#666">8-Bit Oracle</a></div></nav></header><main><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","headline":"When LLM Reasoning Becomes the Pattern - Meta-Classification Failure Modes","description":"Hard constraints beat soft self-regulation when an LLM's reasoning converges to a template.","datePublished":"2025-09-27T00:00:00.000Z","dateModified":"2025-09-27T00:00:00.000Z","author":{"@type":"Person","name":"Augustin Chan","url":"https://augustinchan.dev","sameAs":["https://x.com/augchan42","https://github.com/augchan42"]},"publisher":{"@type":"Person","name":"Augustin Chan","url":"https://augustinchan.dev"},"url":"https://augustinchan.dev/posts/2025-09-27-llm-reasoning-pattern-classification-failure-modes","mainEntityOfPage":{"@type":"WebPage","@id":"https://augustinchan.dev/posts/2025-09-27-llm-reasoning-pattern-classification-failure-modes"},"image":"https://augustinchan.dev/img/Xrn0Id68_400x400.jpg"}</script><article><header style="margin-bottom:2rem"><h1 style="font-size:2.5em;margin-bottom:0.5rem">When LLM Reasoning Becomes the Pattern - Meta-Classification Failure Modes</h1><div style="color:#666;font-size:1em;margin-bottom:1rem">September 27, 2025</div><p style="font-size:1.1em;color:#555;font-style:italic;margin-bottom:2rem">Hard constraints beat soft self-regulation when an LLM&#x27;s reasoning converges to a template.</p></header><div>Loading...</div><aside style="margin-top:4rem;padding-top:2rem;border-top:2px solid #ddd"><h2 style="font-size:1.5em;margin-bottom:1.5rem">Related Posts</h2><div style="display:flex;flex-direction:column;gap:1.5rem"><article style="padding:1.25rem;border:1px solid #ddd;border-radius:8px;background-color:#fafafa"><a style="font-size:1.1em;font-weight:bold;text-decoration:none;color:#333" href="/posts/2025-09-21-evolutionary-adrs-first-principles">Evolutionary ADRs: Writing Architecture Decision Records from First Principles</a><p style="font-size:0.95em;color:#555;margin:0.5rem 0 0 0;line-height:1.5">Why creating ADRs during development, not before it, leads to more honest and valuable documentation of your architectural decisions.</p><div style="font-size:0.85em;color:#888;margin-top:0.5rem">September 21, 2025</div></article><article style="padding:1.25rem;border:1px solid #ddd;border-radius:8px;background-color:#fafafa"><a style="font-size:1.1em;font-weight:bold;text-decoration:none;color:#333" href="/posts/2025-09-14-trusting-instincts-ai-architecture">Trusting Your Instincts: When AI Suggests Complex Solutions</a><p style="font-size:0.95em;color:#555;margin:0.5rem 0 0 0;line-height:1.5">A debugging session reveals why your gut feeling about &#x27;two sets of items&#x27; was right - and how to guide AI toward simpler, better solutions.</p><div style="font-size:0.85em;color:#888;margin-top:0.5rem">September 14, 2025</div></article><article style="padding:1.25rem;border:1px solid #ddd;border-radius:8px;background-color:#fafafa"><a style="font-size:1.1em;font-weight:bold;text-decoration:none;color:#333" href="/posts/2025-09-02-dspy-voice-evolution-authenticity">From Mimicry to Authenticity: Systematic Voice Evolution in DSPy</a><p style="font-size:0.95em;color:#555;margin:0.5rem 0 0 0;line-height:1.5">Replace style copying with principled search: explore a multi-dimensional voice space and use Pareto-optimal selection to shape an original AI voice.</p><div style="font-size:0.85em;color:#888;margin-top:0.5rem">September 2, 2025</div></article></div></aside></article><!--$--><!--/$--></main><footer style="border-top:1px solid #ddd;padding-top:2rem;margin-top:4rem;text-align:center;color:#666">© 2025 Augustin Chan aug@digitalrain.studio</footer></div><script>
            // Service worker cleanup for legacy site versions
            if ('serviceWorker' in navigator) {
              navigator.serviceWorker.getRegistrations().then(function(registrations) {
                for(let registration of registrations) {
                  registration.unregister();
                }
              });

              // Register cleanup service worker
              navigator.serviceWorker.register('/sw.js').then(function(registration) {
                console.log('Cleanup SW registered');
              }).catch(function(error) {
                console.log('Cleanup SW registration failed');
              });
            }
          </script><script src="/_next/static/chunks/webpack-6e1697fef140febb.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[9586,[\"97\",\"static/chunks/102969c4-60ccef36263800a0.js\",\"28\",\"static/chunks/64d1c0c4-a3ef1c2074d5cee5.js\",\"205\",\"static/chunks/205-e96f68d7203b15f6.js\",\"3\",\"static/chunks/3-63e812f17dc5f3c8.js\",\"858\",\"static/chunks/app/posts/%5Bslug%5D/page-149ed8916e948834.js\"],\"\"]\n3:I[4308,[],\"\"]\n4:I[834,[],\"\"]\n5:I[560,[\"205\",\"static/chunks/205-e96f68d7203b15f6.js\",\"177\",\"static/chunks/app/layout-6e1c24235b3dba30.js\"],\"\"]\n6:I[8641,[\"205\",\"static/chunks/205-e96f68d7203b15f6.js\",\"177\",\"static/chunks/app/layout-6e1c24235b3dba30.js\"],\"Analytics\"]\nb:I[9216,[],\"\"]\n:HL[\"/_next/static/css/d030d367e034049b.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"JU7X53FC3NyGNUqwbDOVC\",\"p\":\"\",\"c\":[\"\",\"posts\",\"2025-09-27-llm-reasoning-pattern-classification-failure-modes\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"posts\",{\"children\":[[\"slug\",\"2025-09-27-llm-reasoning-pattern-classification-failure-modes\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/d030d367e034049b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"div\",null,{\"style\":{\"maxWidth\":\"1000px\",\"margin\":\"0 auto\",\"padding\":\"2rem\"},\"children\":[[\"$\",\"header\",null,{\"style\":{\"borderBottom\":\"2px solid #333\",\"paddingBottom\":\"1rem\",\"marginBottom\":\"2rem\"},\"children\":[\"$\",\"nav\",null,{\"style\":{\"display\":\"flex\",\"justifyContent\":\"space-between\",\"alignItems\":\"center\",\"flexWrap\":\"wrap\",\"gap\":\"1rem\"},\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"$L2\",null,{\"href\":\"/\",\"style\":{\"fontSize\":\"1.6rem\",\"fontWeight\":\"bold\",\"textDecoration\":\"none\",\"color\":\"#333\"},\"children\":\"Augustin Chan\"}],[\"$\",\"div\",null,{\"style\":{\"marginTop\":\"0.5rem\"},\"children\":\"Building systems that reason\"}]]}],[\"$\",\"div\",null,{\"style\":{\"display\":\"flex\",\"gap\":\"1.5rem\",\"flexWrap\":\"wrap\"},\"children\":[[\"$\",\"$L2\",null,{\"href\":\"/\",\"style\":{\"textDecoration\":\"none\",\"color\":\"#666\"},\"children\":\"Home\"}],[\"$\",\"$L2\",null,{\"href\":\"/about\",\"style\":{\"textDecoration\":\"none\",\"color\":\"#666\"},\"children\":\"About\"}],[\"$\",\"$L2\",null,{\"href\":\"/blog\",\"style\":{\"textDecoration\":\"none\",\"color\":\"#666\"},\"children\":\"Blog\"}],[\"$\",\"a\",null,{\"href\":\"https://8bitoracle.ai\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"style\":{\"textDecoration\":\"none\",\"color\":\"#666\"},\"children\":\"8-Bit Oracle\"}]]}]]}]}],[\"$\",\"main\",null,{\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"style\":{\"borderTop\":\"1px solid #ddd\",\"paddingTop\":\"2rem\",\"marginTop\":\"4rem\",\"textAlign\":\"center\",\"color\":\"#666\"},\"children\":\"© 2025 Augustin Chan aug@digitalrain.studio\"}]]}],[[\"$\",\"$L5\",null,{\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-077BT1Q7PJ\",\"strategy\":\"afterInteractive\"}],[\"$\",\"$L5\",null,{\"id\":\"google-analytics\",\"strategy\":\"afterInteractive\",\"children\":\"\\n          window.dataLayer = window.dataLayer || [];\\n          function gtag(){dataLayer.push(arguments);}\\n          gtag('js', new Date());\\n          gtag('config', 'G-077BT1Q7PJ');\\n        \"}]],[\"$\",\"$L6\",null,{}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n            // Service worker cleanup for legacy site versions\\n            if ('serviceWorker' in navigator) {\\n              navigator.serviceWorker.getRegistrations().then(function(registrations) {\\n                for(let registration of registrations) {\\n                  registration.unregister();\\n                }\\n              });\\n\\n              // Register cleanup service worker\\n              navigator.serviceWorker.register('/sw.js').then(function(registration) {\\n                console.log('Cleanup SW registered');\\n              }).catch(function(error) {\\n                console.log('Cleanup SW registration failed');\\n              });\\n            }\\n          \"}}]]}]}]]}],{\"children\":[\"posts\",\"$L7\",{\"children\":[[\"slug\",\"2025-09-27-llm-reasoning-pattern-classification-failure-modes\",\"d\"],\"$L8\",{\"children\":[\"__PAGE__\",\"$L9\",{},null,false]},null,false]},null,false]},null,false],\"$La\",false]],\"m\":\"$undefined\",\"G\":[\"$b\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"d:I[7921,[],\"OutletBoundary\"]\nf:I[2140,[],\"AsyncMetadataOutlet\"]\n11:I[7921,[],\"ViewportBoundary\"]\n13:I[7921,[],\"MetadataBoundary\"]\n14:\"$Sreact.suspense\"\n7:[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]\n8:[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]\n9:[\"$\",\"$1\",\"c\",{\"children\":[\"$Lc\",null,[\"$\",\"$Ld\",null,{\"children\":[\"$Le\",[\"$\",\"$Lf\",null,{\"promise\":\"$@10\"}]]}]]}]\na:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L11\",null,{\"children\":\"$L12\"}],null],[\"$\",\"$L13\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$14\",null,{\"fallback\":null,\"children\":\"$L15\"}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"16:I[7702,[\"97\",\"static/chunks/102969c4-60ccef36263800a0.js\",\"28\",\"static/chunks/64d1c0c4-a3ef1c2074d5cee5.js\",\"205\",\"static/chunks/205-e96f68d7203b15f6.js\",\"3\",\"static/chunks/3-63e812f17dc5f3c8.js\",\"858\",\"static/chunks/app/posts/%5Bslug%5D/page-149ed8916e948834.js\"],\"default\",1]\n17:T1e6d,"])</script><script>self.__next_f.push([1,"\n**TL;DR**  \nI caught my Twitter agent [Pix](https://x.com/pixdotpink) \"reasoning\" itself into sameness: its justification text varied, but the rhetoric converged to the same opener (\"Ever…\"). Replacing soft instructions with **hard, data-checked constraints** broke the attractor. Use LLMs to *generate*; use **metrics** to *regulate*.\n\n**Abstract:**  \nI observed an LLM failure mode where meta-reasoning—\"pivot to visceral,\" \"avoid declaratives,\" etc.—became a **template attractor**. Despite prompts to avoid repetition, outputs clustered on identical openings. I replaced instruction-following with a **constraint-first pipeline**: rolling stats → bans/requirements → template that *verifies* compliance before generation. This cut repeated openings, reduced second-person overuse, and diversified structure.\n\n**Estimated reading time:** _8 minutes_\n\n{/* Force deployment refresh - Updated 2025-09-27T09:52:00Z */}\n\n## The Problem: Reasoning that masquerades as novelty\n\n**Meta-pattern (definition):** the repeatable *shape* of text (opening n-gram, sentence mood, rhetorical hook), independent of specific words.\n\nIn my last 10 posts:\n\n* Openings: \"**Ever…**\" (8), \"Okay so\" (2)\n* Structure: **Questions:** 7/10; **Second-person:** 9/10\n* Word overuse: *ever* (8), *your* (9)\n\nThe chain-of-thought varied (\"pivot to visceral first-person…\") while the **shape** stayed the same.\n\nWhen I examined the reasoning traces, they looked sophisticated:\n\n\u003e \"Recent posts were declarative, so I should pivot to visceral first-person approach...\"\n\u003e \"To avoid the pattern of detached observations, I'll use experiential hooks...\"\n\u003e \"Breaking from analytical tone with personal reflection...\"\n\nThe reasoning *looked* different each time, but the output was identical. The LLM had learned that \"Ever...\" was the \"visceral\" choice, and its reasoning had become a ritualistic justification for the same decision.\n\n### Why this happens\n\n1. **Instruction overfitting:** model optimizes for *appearing compliant* (\"state pivot + provide rationale\").\n2. **Context echo:** prior outputs in context teach the **shape** to reproduce.\n3. **Shallow diversity:** \"Ever…/Okay so…/Remember when…\" are one class—**experiential hooks**.\n4. **Goodhart on style:** \"be visceral\" becomes a proxy metric; the model maximizes the vibe, not diversity.\n\nThe \"reasoning\" had become a disguised heuristic:\n\n```\nIF instruction = \"avoid patterns\"\nTHEN output = \"Ever...\" + explanation_template\n```\n\n## Implementation: Metrics as regulator, model as generator\n\n### 1) Feature tracking (rolling window K=10–30)\n\n```typescript\nconst wordCounts = analyzeWordFrequency(recentPosts);\nconst openingNgrams = trackOpeningPhrases(recentPosts, {n:2});\nconst structure = analyzeStructure(recentPosts); // ? ! 2nd-person, sentence moods\n```\n\n### 2) Policy constraints (bans + requirements)\n\n```\nPATTERN ANALYSIS\n- Overused words: ever:8, your:9\n- Openings: \"ever\":8, \"okay so\":2\n- Structure: Questions:7, SecondPerson:9\n\nPOLICY (K=10)\n- BAN opening ∈ {\"ever\"} if count ≥ 3\n- BAN question form if proportion ≥ 0.6\n- BAN 2nd-person if proportion ≥ 0.7\n- REQUIRE {declarative ∨ observational} mood\n```\n\n### 3) Template overhaul: verify → then generate\n\n```typescript\nconst template = `\nCONSTRAINT CHECK:\n- Opening not in {${forbiddenOpeners.join(\", \")}}  -\u003e [OK/FAIL]\n- Second-person proportion \u003c ${thr.secondPerson}    -\u003e [OK/FAIL]\n- Question proportion \u003c ${thr.questions}            -\u003e [OK/FAIL]\n- Required mood present (declarative/observational) -\u003e [OK/FAIL]\nEmit post only if all checks OK; otherwise propose an allowed alternative.\n`;\n```\n\n## Before/After (representative)\n\n**Before (violates):**\n\"**Ever** notice your timelines turn into mirrors? …\" *(question + second-person + experiential hook)*\n\n**After (passes):**\n\"Timelines behave like mirrors: repeated forms reduce reach. Today's note documents a fix—ban dominant hooks for a windowed interval.\" *(declarative + observational; no 2nd-person; new opener)*\n\n## Results (early evidence)\n\n**Post-constraint outputs (2 samples):**\n\n1. \"Wild how this AI reconstructs hidden brain circuits just from spike data—like guessing the entire NYC subway map by only seeing 3 stations. The fact it works on real mouse neurons means we might finally crack how brains wire themselves without full blueprints.\"\n\n2. \"ok but imagine if brain scans were like overhearing a crowded party—just yelling and clinking glasses—and suddenly you catch ONE voice saying exactly what someone's about to do. that's what this team just figured out how to isolate in the noise\"\n\n**Observable changes:**\n* **Opening diversity:** \"Wild how...\" vs \"ok but imagine...\" (no \"Ever...\" repetition)\n* **Structure variety:** declarative statement vs hypothetical scenario\n* **Second-person usage:** eliminated from first post, minimal in second (\"you catch\")\n* **Rhetorical approach:** technical analogy vs conversational metaphor\n\nSample size is limited (N=2), but the constraint system appears to be preventing the previous \"Ever...\" attractor pattern. Longer evaluation needed to confirm sustained diversity.\n\n## Portable playbook\n\n* **Ladder of constraints:** lexical → syntactic → rhetorical → discourse/intent → semantic cluster.\n* **Cooldowns:** when a feature crosses threshold, put it on a timed banlist.\n* **Exploration pressure:** if similarity \u003e τ, inject an alternative *rhetorical shape* (e.g., aphorism, mini-narrative).\n* **External validation:** scorecards on diversity + real-world KPIs (bookmarks/replies) by bucket.\n\n## Limitations \u0026 failure modes\n\n* **Constraint gaming:** the model paraphrases the same hook. *Mitigation:* include rhetorical/intent classifiers, not just words.\n* **Over-constraint blandness:** diversity without soul. *Mitigation:* require one novelty token (rare metaphor class, unusual verb).\n* **Context poisoning:** long exemplars steer shape. *Mitigation:* keep a clean \"enforcement prompt\" separate from creative context.\n\n## Takeaway\n\nKeep LLM reasoning—but make it reason over crystal-clear aggregates.\nRegulation lives in data and policy (counts, proportions, thresholds, cooldowns). Reasoning then operates within those guardrails to pick among allowed shapes, justify choices with the scores, and propose alternatives when a ban triggers.\n\nControl loop (one line):\naggregate → score → apply policy → reason-with-scores → generate → verify.\n\nWhat changes in practice:\n\nThe scoreboard is non-negotiable (e.g., opening_ever=8/10, q_rate=0.7); the model can’t debate it.\n\nThe model reasons about trade-offs inside the allowed set (e.g., choose observational over question + avoid 2nd-person).\n\nIf reasoning starts ritualizing again, tighten the aggregates or policy, not the prose.\n\nThe two fresh samples illustrate this: once the banlist and thresholds were explicit, the model’s reasoning shifted from “perform visceral” to selecting a different rhetorical shape that satisfied the scores—diversifying openings without gaming the rules.\n\n### Key insights for AI system builders\n\nThis failure mode applies beyond content generation to any system where:\n- LLMs are asked to avoid their own patterns\n- Self-regulation through reasoning is expected\n- Quality control depends on LLM judgment rather than metrics\n\n**LLM \"reasoning\" can become a disguised heuristic.** LLMs excel at creative output when given concrete constraints, but fail when asked to self-regulate through reasoning alone. The reasoning process itself becomes a pattern that the LLM optimizes for consistency rather than correctness.\n\nReal reasoning would have been: \"I've used 'Ever' 8 times, so I need a completely different approach.\"\n\nWhat we got was: \"Recent posts were declarative, so 'Ever...' is the visceral choice.\"\n\n---"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"BlogPosting\\\",\\\"headline\\\":\\\"When LLM Reasoning Becomes the Pattern - Meta-Classification Failure Modes\\\",\\\"description\\\":\\\"Hard constraints beat soft self-regulation when an LLM's reasoning converges to a template.\\\",\\\"datePublished\\\":\\\"2025-09-27T00:00:00.000Z\\\",\\\"dateModified\\\":\\\"2025-09-27T00:00:00.000Z\\\",\\\"author\\\":{\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"Augustin Chan\\\",\\\"url\\\":\\\"https://augustinchan.dev\\\",\\\"sameAs\\\":[\\\"https://x.com/augchan42\\\",\\\"https://github.com/augchan42\\\"]},\\\"publisher\\\":{\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"Augustin Chan\\\",\\\"url\\\":\\\"https://augustinchan.dev\\\"},\\\"url\\\":\\\"https://augustinchan.dev/posts/2025-09-27-llm-reasoning-pattern-classification-failure-modes\\\",\\\"mainEntityOfPage\\\":{\\\"@type\\\":\\\"WebPage\\\",\\\"@id\\\":\\\"https://augustinchan.dev/posts/2025-09-27-llm-reasoning-pattern-classification-failure-modes\\\"},\\\"image\\\":\\\"https://augustinchan.dev/img/Xrn0Id68_400x400.jpg\\\"}\"}}],[\"$\",\"article\",null,{\"children\":[[\"$\",\"header\",null,{\"style\":{\"marginBottom\":\"2rem\"},\"children\":[[\"$\",\"h1\",null,{\"style\":{\"fontSize\":\"2.5em\",\"marginBottom\":\"0.5rem\"},\"children\":\"When LLM Reasoning Becomes the Pattern - Meta-Classification Failure Modes\"}],[\"$\",\"div\",null,{\"style\":{\"color\":\"#666\",\"fontSize\":\"1em\",\"marginBottom\":\"1rem\"},\"children\":\"September 27, 2025\"}],[\"$\",\"p\",null,{\"style\":{\"fontSize\":\"1.1em\",\"color\":\"#555\",\"fontStyle\":\"italic\",\"marginBottom\":\"2rem\"},\"children\":\"Hard constraints beat soft self-regulation when an LLM's reasoning converges to a template.\"}]]}],[\"$\",\"$L16\",null,{\"content\":\"$17\"}],\"$L18\"]}]]\n"])</script><script>self.__next_f.push([1,"18:[\"$\",\"aside\",null,{\"style\":{\"marginTop\":\"4rem\",\"paddingTop\":\"2rem\",\"borderTop\":\"2px solid #ddd\"},\"children\":[[\"$\",\"h2\",null,{\"style\":{\"fontSize\":\"1.5em\",\"marginBottom\":\"1.5rem\"},\"children\":\"Related Posts\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"flex\",\"flexDirection\":\"column\",\"gap\":\"1.5rem\"},\"children\":[[\"$\",\"article\",\"2025-09-21-evolutionary-adrs-first-principles\",{\"style\":{\"padding\":\"1.25rem\",\"border\":\"1px solid #ddd\",\"borderRadius\":\"8px\",\"backgroundColor\":\"#fafafa\"},\"children\":[[\"$\",\"$L2\",null,{\"href\":\"/posts/2025-09-21-evolutionary-adrs-first-principles\",\"style\":{\"fontSize\":\"1.1em\",\"fontWeight\":\"bold\",\"textDecoration\":\"none\",\"color\":\"#333\"},\"children\":\"Evolutionary ADRs: Writing Architecture Decision Records from First Principles\"}],[\"$\",\"p\",null,{\"style\":{\"fontSize\":\"0.95em\",\"color\":\"#555\",\"margin\":\"0.5rem 0 0 0\",\"lineHeight\":\"1.5\"},\"children\":\"Why creating ADRs during development, not before it, leads to more honest and valuable documentation of your architectural decisions.\"}],[\"$\",\"div\",null,{\"style\":{\"fontSize\":\"0.85em\",\"color\":\"#888\",\"marginTop\":\"0.5rem\"},\"children\":\"September 21, 2025\"}]]}],[\"$\",\"article\",\"2025-09-14-trusting-instincts-ai-architecture\",{\"style\":{\"padding\":\"1.25rem\",\"border\":\"1px solid #ddd\",\"borderRadius\":\"8px\",\"backgroundColor\":\"#fafafa\"},\"children\":[[\"$\",\"$L2\",null,{\"href\":\"/posts/2025-09-14-trusting-instincts-ai-architecture\",\"style\":{\"fontSize\":\"1.1em\",\"fontWeight\":\"bold\",\"textDecoration\":\"none\",\"color\":\"#333\"},\"children\":\"Trusting Your Instincts: When AI Suggests Complex Solutions\"}],[\"$\",\"p\",null,{\"style\":{\"fontSize\":\"0.95em\",\"color\":\"#555\",\"margin\":\"0.5rem 0 0 0\",\"lineHeight\":\"1.5\"},\"children\":\"A debugging session reveals why your gut feeling about 'two sets of items' was right - and how to guide AI toward simpler, better solutions.\"}],[\"$\",\"div\",null,{\"style\":{\"fontSize\":\"0.85em\",\"color\":\"#888\",\"marginTop\":\"0.5rem\"},\"children\":\"September 14, 2025\"}]]}],[\"$\",\"article\",\"2025-09-02-dspy-voice-evolution-authenticity\",{\"style\":{\"padding\":\"1.25rem\",\"border\":\"1px solid #ddd\",\"borderRadius\":\"8px\",\"backgroundColor\":\"#fafafa\"},\"children\":[[\"$\",\"$L2\",null,{\"href\":\"/posts/2025-09-02-dspy-voice-evolution-authenticity\",\"style\":{\"fontSize\":\"1.1em\",\"fontWeight\":\"bold\",\"textDecoration\":\"none\",\"color\":\"#333\"},\"children\":\"From Mimicry to Authenticity: Systematic Voice Evolution in DSPy\"}],[\"$\",\"p\",null,{\"style\":{\"fontSize\":\"0.95em\",\"color\":\"#555\",\"margin\":\"0.5rem 0 0 0\",\"lineHeight\":\"1.5\"},\"children\":\"Replace style copying with principled search: explore a multi-dimensional voice space and use Pareto-optimal selection to shape an original AI voice.\"}],[\"$\",\"div\",null,{\"style\":{\"fontSize\":\"0.85em\",\"color\":\"#888\",\"marginTop\":\"0.5rem\"},\"children\":\"September 2, 2025\"}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"12:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\ne:null\n"])</script><script>self.__next_f.push([1,"10:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"When LLM Reasoning Becomes the Pattern - Meta-Classification Failure Modes | Augustin Chan\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Hard constraints beat soft self-regulation when an LLM's reasoning converges to a template.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"author\",\"href\":\"https://augustinchan.dev\"}],[\"$\",\"meta\",\"3\",{\"name\":\"author\",\"content\":\"Augustin Chan\"}],[\"$\",\"meta\",\"4\",{\"name\":\"keywords\",\"content\":\"AI,Machine Learning,Web3,Software Engineering,React,Next.js,TypeScript,Blog\"}],[\"$\",\"meta\",\"5\",{\"name\":\"creator\",\"content\":\"Augustin Chan\"}],[\"$\",\"meta\",\"6\",{\"name\":\"publisher\",\"content\":\"Augustin Chan\"}],[\"$\",\"meta\",\"7\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"8\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"9\",{\"rel\":\"canonical\",\"href\":\"https://augustinchan.dev/posts/2025-09-27-llm-reasoning-pattern-classification-failure-modes\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:title\",\"content\":\"When LLM Reasoning Becomes the Pattern - Meta-Classification Failure Modes\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:description\",\"content\":\"Hard constraints beat soft self-regulation when an LLM's reasoning converges to a template.\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:url\",\"content\":\"https://augustinchan.dev/posts/2025-09-27-llm-reasoning-pattern-classification-failure-modes\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:site_name\",\"content\":\"Augustin Chan\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:image\",\"content\":\"https://augustinchan.dev/img/Xrn0Id68_400x400.jpg\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:image:width\",\"content\":\"400\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:image:height\",\"content\":\"400\"}],[\"$\",\"meta\",\"18\",{\"property\":\"og:image:alt\",\"content\":\"When LLM Reasoning Becomes the Pattern - Meta-Classification Failure Modes\"}],[\"$\",\"meta\",\"19\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"20\",{\"property\":\"article:published_time\",\"content\":\"2025-09-27T00:00:00.000Z\"}],[\"$\",\"meta\",\"21\",{\"property\":\"article:author\",\"content\":\"Augustin Chan\"}],[\"$\",\"meta\",\"22\",{\"property\":\"article:section\",\"content\":\"Technology\"}],[\"$\",\"meta\",\"23\",{\"property\":\"article:tag\",\"content\":\"AI\"}],[\"$\",\"meta\",\"24\",{\"property\":\"article:tag\",\"content\":\"Machine Learning\"}],[\"$\",\"meta\",\"25\",{\"property\":\"article:tag\",\"content\":\"Web3\"}],[\"$\",\"meta\",\"26\",{\"property\":\"article:tag\",\"content\":\"Software Engineering\"}],[\"$\",\"meta\",\"27\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"28\",{\"name\":\"twitter:creator\",\"content\":\"@augchan42\"}],[\"$\",\"meta\",\"29\",{\"name\":\"twitter:title\",\"content\":\"When LLM Reasoning Becomes the Pattern - Meta-Classification Failure Modes\"}],[\"$\",\"meta\",\"30\",{\"name\":\"twitter:description\",\"content\":\"Hard constraints beat soft self-regulation when an LLM's reasoning converges to a template.\"}],[\"$\",\"meta\",\"31\",{\"name\":\"twitter:image\",\"content\":\"https://augustinchan.dev/img/Xrn0Id68_400x400.jpg\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"15:\"$10:metadata\"\n"])</script></body></html>
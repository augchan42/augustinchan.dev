1:"$Sreact.fragment"
2:I[9586,["97","static/chunks/102969c4-60ccef36263800a0.js","28","static/chunks/64d1c0c4-a3ef1c2074d5cee5.js","205","static/chunks/205-e96f68d7203b15f6.js","3","static/chunks/3-63e812f17dc5f3c8.js","858","static/chunks/app/posts/%5Bslug%5D/page-149ed8916e948834.js"],""]
3:I[4308,[],""]
4:I[834,[],""]
5:I[560,["205","static/chunks/205-e96f68d7203b15f6.js","177","static/chunks/app/layout-6e1c24235b3dba30.js"],""]
6:I[8641,["205","static/chunks/205-e96f68d7203b15f6.js","177","static/chunks/app/layout-6e1c24235b3dba30.js"],"Analytics"]
b:I[9216,[],""]
:HL["/_next/static/css/d030d367e034049b.css","style"]
0:{"P":null,"b":"u_Sey-ZLcWxz-wW4LxgN4","p":"","c":["","posts","2025-09-14-trusting-instincts-ai-architecture"],"i":false,"f":[[["",{"children":["posts",{"children":[["slug","2025-09-14-trusting-instincts-ai-architecture","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/d030d367e034049b.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"suppressHydrationWarning":true,"children":[["$","div",null,{"style":{"maxWidth":"1000px","margin":"0 auto","padding":"2rem"},"children":[["$","header",null,{"style":{"borderBottom":"2px solid #333","paddingBottom":"1rem","marginBottom":"2rem"},"children":["$","nav",null,{"style":{"display":"flex","justifyContent":"space-between","alignItems":"center","flexWrap":"wrap","gap":"1rem"},"children":[["$","div",null,{"children":[["$","$L2",null,{"href":"/","style":{"fontSize":"1.6rem","fontWeight":"bold","textDecoration":"none","color":"#333"},"children":"Augustin Chan"}],["$","div",null,{"style":{"marginTop":"0.5rem"},"children":"Building systems that reason"}]]}],["$","div",null,{"style":{"display":"flex","gap":"1.5rem","flexWrap":"wrap"},"children":[["$","$L2",null,{"href":"/","style":{"textDecoration":"none","color":"#666"},"children":"Home"}],["$","$L2",null,{"href":"/about","style":{"textDecoration":"none","color":"#666"},"children":"About"}],["$","$L2",null,{"href":"/blog","style":{"textDecoration":"none","color":"#666"},"children":"Blog"}],["$","a",null,{"href":"https://8bitoracle.ai","target":"_blank","rel":"noopener noreferrer","style":{"textDecoration":"none","color":"#666"},"children":"8-Bit Oracle"}]]}]]}]}],["$","main",null,{"children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","footer",null,{"style":{"borderTop":"1px solid #ddd","paddingTop":"2rem","marginTop":"4rem","textAlign":"center","color":"#666"},"children":"Â© 2025 Augustin Chan aug@digitalrain.studio"}]]}],[["$","$L5",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-077BT1Q7PJ","strategy":"afterInteractive"}],["$","$L5",null,{"id":"google-analytics","strategy":"afterInteractive","children":"\n          window.dataLayer = window.dataLayer || [];\n          function gtag(){dataLayer.push(arguments);}\n          gtag('js', new Date());\n          gtag('config', 'G-077BT1Q7PJ');\n        "}]],["$","$L6",null,{}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n            // Service worker cleanup for legacy site versions\n            if ('serviceWorker' in navigator) {\n              navigator.serviceWorker.getRegistrations().then(function(registrations) {\n                for(let registration of registrations) {\n                  registration.unregister();\n                }\n              });\n\n              // Register cleanup service worker\n              navigator.serviceWorker.register('/sw.js').then(function(registration) {\n                console.log('Cleanup SW registered');\n              }).catch(function(error) {\n                console.log('Cleanup SW registration failed');\n              });\n            }\n          "}}]]}]}]]}],{"children":["posts","$L7",{"children":[["slug","2025-09-14-trusting-instincts-ai-architecture","d"],"$L8",{"children":["__PAGE__","$L9",{},null,false]},null,false]},null,false]},null,false],"$La",false]],"m":"$undefined","G":["$b",[]],"s":false,"S":true}
d:I[7921,[],"OutletBoundary"]
f:I[2140,[],"AsyncMetadataOutlet"]
11:I[7921,[],"ViewportBoundary"]
13:I[7921,[],"MetadataBoundary"]
14:"$Sreact.suspense"
7:["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
8:["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
9:["$","$1","c",{"children":["$Lc",null,["$","$Ld",null,{"children":["$Le",["$","$Lf",null,{"promise":"$@10"}]]}]]}]
a:["$","$1","h",{"children":[null,[["$","$L11",null,{"children":"$L12"}],null],["$","$L13",null,{"children":["$","div",null,{"hidden":true,"children":["$","$14",null,{"fallback":null,"children":"$L15"}]}]}]]}]
16:I[7702,["97","static/chunks/102969c4-60ccef36263800a0.js","28","static/chunks/64d1c0c4-a3ef1c2074d5cee5.js","205","static/chunks/205-e96f68d7203b15f6.js","3","static/chunks/3-63e812f17dc5f3c8.js","858","static/chunks/app/posts/%5Bslug%5D/page-149ed8916e948834.js"],"default",1]
17:T134f,

**Abstract:**  
When debugging a React selection bug, AI suggested syncing two data sources. My instinct said "this feels wrong" - and it was. A quick web search confirmed that maintaining duplicate state violates fundamental React principles. This post explores how to recognize when AI is overcomplicating solutions and trust your architectural instincts.

**Estimated reading time:** _5 minutes_

I had one of those debugging sessions recently that perfectly illustrates why experienced developers need to trust their instincts when working with AI assistants, even when the AI's suggestions seem technically sound.

## The Problem

The issue was straightforward: search and filtering worked correctly (logs showed proper filtering from 20 items down to 2), but clicking on individual content items wasn't being detected. The AI assistant quickly identified the root cause:

> The toggleContentSelection function from useContentSelection hook is looking for items in the contentStore's inputMaterial, but we're displaying items from SimpleContentSearch's inputMaterial. These are two different data sources.

## The AI's Solution

The AI proposed what seemed like a reasonable fix:

> We need to sync the SimpleContentSearch results to the contentStore so both data sources match.

It even provided code examples and explained the technical approach. The solution was technically correct and would have worked.

## The Gut Feeling

But something felt off. I had that nagging feeling developers get when they see architectural patterns that just don't sit right. Specifically, I was wary of having "two sets of items" - one in the contentStore and one from SimpleContentSearch results.

I asked the AI to search for best practices around this pattern, and the results confirmed my suspicion.

## The Web Search Results

The search revealed that maintaining duplicate data sources is explicitly called out as an anti-pattern in React state management:

> "Avoid redundant and duplicate state so that you don't need to keep them in sync" - React Docs

> "There should be a single 'source of truth' for any data that changes in a React application"

> "This issue destroys the single source of truth concept... It is a bad practice and should be avoided"

## Why Two Data Sources is Bad

The search results highlighted exactly why my instinct was right:

1. **Sync Hell**: Updates to one don't automatically update the other
2. **Bug Factory**: Components can display different data from same API
3. **Race Conditions**: User sees stale data while new data loads
4. **Memory Waste**: Duplicate data storage
5. **Mental Overhead**: Developers must track multiple sources

## The Better Solution

Instead of syncing two data sources, the proper 2025 best practice solutions are:

**Option 1: Single Store (Recommended)**
```javascript
// SimpleContentSearch becomes stateless - just triggers store actions
const handleSearch = (query) => {
  contentStore.searchContent(query) // Updates single source
}
```

**Option 2: Derived State**
```javascript
// One source, derive the other
const searchResults = useMemo(() =>
  applyFilters(contentStore.inputMaterial, filters)
, [contentStore.inputMaterial, filters])
```

**Option 3: Event-Driven**
```javascript
// SearchContentSearch emits events, contentStore listens
searchService.on('results', (data) => contentStore.setInputMaterial(data))
```

## The Lesson

This debugging session perfectly illustrates a key principle: **trust your architectural instincts, even when AI provides technically correct solutions.**

The AI was right about the immediate fix, but wrong about the architectural approach. My gut feeling about "two sets of items" was spot-on - this dual-source architecture is exactly what caused the selection bug we were experiencing.

## When to Push Back on AI

Here are the red flags that should trigger your architectural instincts:

- **Duplicate data sources**: If you're maintaining the same data in multiple places
- **Complex sync mechanisms**: When the solution involves keeping things "in sync"
- **State copying**: Moving data from one store to another instead of deriving it
- **Multiple sources of truth**: When different parts of your app use different data sources

## The Meta-Lesson

The most valuable part of this debugging session wasn't fixing the bug - it was learning to recognize when AI is suggesting solutions that work but violate fundamental principles. The AI was focused on the immediate technical problem, while my instinct was focused on the broader architectural health of the system.

Sometimes the best debugging tool isn't a debugger or an AI assistant - it's that nagging feeling that something just doesn't feel right architecturally. Trust that feeling.

**Confidence: 95%** - This is a well-established React pattern, and the web search results from official React documentation confirm the anti-pattern nature of duplicate state sources.
c:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"Trusting Your Instincts: When AI Suggests Complex Solutions\",\"description\":\"A debugging session reveals why your gut feeling about 'two sets of items' was right - and how to guide AI toward simpler, better solutions.\",\"datePublished\":\"2025-09-14T00:00:00.000Z\",\"dateModified\":\"2025-09-14T00:00:00.000Z\",\"author\":{\"@type\":\"Person\",\"name\":\"Augustin Chan\",\"url\":\"https://augustinchan.dev\",\"sameAs\":[\"https://x.com/augchan42\",\"https://github.com/augchan42\"]},\"publisher\":{\"@type\":\"Person\",\"name\":\"Augustin Chan\",\"url\":\"https://augustinchan.dev\"},\"url\":\"https://augustinchan.dev/posts/2025-09-14-trusting-instincts-ai-architecture\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https://augustinchan.dev/posts/2025-09-14-trusting-instincts-ai-architecture\"},\"image\":\"https://augustinchan.dev/img/Xrn0Id68_400x400.jpg\"}"}}],["$","article",null,{"children":[["$","header",null,{"style":{"marginBottom":"2rem"},"children":[["$","h1",null,{"style":{"fontSize":"2.5em","marginBottom":"0.5rem"},"children":"Trusting Your Instincts: When AI Suggests Complex Solutions"}],["$","div",null,{"style":{"color":"#666","fontSize":"1em","marginBottom":"1rem"},"children":"September 14, 2025"}],["$","p",null,{"style":{"fontSize":"1.1em","color":"#555","fontStyle":"italic","marginBottom":"2rem"},"children":"A debugging session reveals why your gut feeling about 'two sets of items' was right - and how to guide AI toward simpler, better solutions."}]]}],["$","$L16",null,{"content":"$17"}],"$L18"]}]]
18:["$","aside",null,{"style":{"marginTop":"4rem","paddingTop":"2rem","borderTop":"2px solid #ddd"},"children":[["$","h2",null,{"style":{"fontSize":"1.5em","marginBottom":"1.5rem"},"children":"Related Posts"}],["$","div",null,{"style":{"display":"flex","flexDirection":"column","gap":"1.5rem"},"children":[["$","article","2025-09-27-llm-reasoning-pattern-classification-failure-modes",{"style":{"padding":"1.25rem","border":"1px solid #ddd","borderRadius":"8px","backgroundColor":"#fafafa"},"children":[["$","$L2",null,{"href":"/posts/2025-09-27-llm-reasoning-pattern-classification-failure-modes","style":{"fontSize":"1.1em","fontWeight":"bold","textDecoration":"none","color":"#333"},"children":"When LLM Reasoning Becomes the Pattern - Meta-Classification Failure Modes"}],["$","p",null,{"style":{"fontSize":"0.95em","color":"#555","margin":"0.5rem 0 0 0","lineHeight":"1.5"},"children":"Hard constraints beat soft self-regulation when an LLM's reasoning converges to a template."}],["$","div",null,{"style":{"fontSize":"0.85em","color":"#888","marginTop":"0.5rem"},"children":"September 27, 2025"}]]}],["$","article","2025-09-21-evolutionary-adrs-first-principles",{"style":{"padding":"1.25rem","border":"1px solid #ddd","borderRadius":"8px","backgroundColor":"#fafafa"},"children":[["$","$L2",null,{"href":"/posts/2025-09-21-evolutionary-adrs-first-principles","style":{"fontSize":"1.1em","fontWeight":"bold","textDecoration":"none","color":"#333"},"children":"Evolutionary ADRs: Writing Architecture Decision Records from First Principles"}],["$","p",null,{"style":{"fontSize":"0.95em","color":"#555","margin":"0.5rem 0 0 0","lineHeight":"1.5"},"children":"Why creating ADRs during development, not before it, leads to more honest and valuable documentation of your architectural decisions."}],["$","div",null,{"style":{"fontSize":"0.85em","color":"#888","marginTop":"0.5rem"},"children":"September 21, 2025"}]]}],["$","article","hello-nextra",{"style":{"padding":"1.25rem","border":"1px solid #ddd","borderRadius":"8px","backgroundColor":"#fafafa"},"children":[["$","$L2",null,{"href":"/posts/hello-nextra","style":{"fontSize":"1.1em","fontWeight":"bold","textDecoration":"none","color":"#333"},"children":"Hello Nextra"}],["$","p",null,{"style":{"fontSize":"0.95em","color":"#555","margin":"0.5rem 0 0 0","lineHeight":"1.5"},"children":"Welcome to my new blog powered by Next.js and Nextra"}],["$","div",null,{"style":{"fontSize":"0.85em","color":"#888","marginTop":"0.5rem"},"children":"September 21, 2025"}]]}]]}]]}]
12:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
e:null
10:{"metadata":[["$","title","0",{"children":"Trusting Your Instincts: When AI Suggests Complex Solutions | Augustin Chan"}],["$","meta","1",{"name":"description","content":"A debugging session reveals why your gut feeling about 'two sets of items' was right - and how to guide AI toward simpler, better solutions."}],["$","link","2",{"rel":"author","href":"https://augustinchan.dev"}],["$","meta","3",{"name":"author","content":"Augustin Chan"}],["$","meta","4",{"name":"keywords","content":"AI,Machine Learning,Web3,Software Engineering,React,Next.js,TypeScript,Blog"}],["$","meta","5",{"name":"creator","content":"Augustin Chan"}],["$","meta","6",{"name":"publisher","content":"Augustin Chan"}],["$","meta","7",{"name":"robots","content":"index, follow"}],["$","meta","8",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","9",{"rel":"canonical","href":"https://augustinchan.dev/posts/2025-09-14-trusting-instincts-ai-architecture"}],["$","meta","10",{"property":"og:title","content":"Trusting Your Instincts: When AI Suggests Complex Solutions"}],["$","meta","11",{"property":"og:description","content":"A debugging session reveals why your gut feeling about 'two sets of items' was right - and how to guide AI toward simpler, better solutions."}],["$","meta","12",{"property":"og:url","content":"https://augustinchan.dev/posts/2025-09-14-trusting-instincts-ai-architecture"}],["$","meta","13",{"property":"og:site_name","content":"Augustin Chan"}],["$","meta","14",{"property":"og:locale","content":"en_US"}],["$","meta","15",{"property":"og:image","content":"https://augustinchan.dev/img/Xrn0Id68_400x400.jpg"}],["$","meta","16",{"property":"og:image:width","content":"400"}],["$","meta","17",{"property":"og:image:height","content":"400"}],["$","meta","18",{"property":"og:image:alt","content":"Trusting Your Instincts: When AI Suggests Complex Solutions"}],["$","meta","19",{"property":"og:type","content":"article"}],["$","meta","20",{"property":"article:published_time","content":"2025-09-14T00:00:00.000Z"}],["$","meta","21",{"property":"article:author","content":"Augustin Chan"}],["$","meta","22",{"property":"article:section","content":"Technology"}],["$","meta","23",{"property":"article:tag","content":"AI"}],["$","meta","24",{"property":"article:tag","content":"Machine Learning"}],["$","meta","25",{"property":"article:tag","content":"Web3"}],["$","meta","26",{"property":"article:tag","content":"Software Engineering"}],["$","meta","27",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","28",{"name":"twitter:creator","content":"@augchan42"}],["$","meta","29",{"name":"twitter:title","content":"Trusting Your Instincts: When AI Suggests Complex Solutions"}],["$","meta","30",{"name":"twitter:description","content":"A debugging session reveals why your gut feeling about 'two sets of items' was right - and how to guide AI toward simpler, better solutions."}],["$","meta","31",{"name":"twitter:image","content":"https://augustinchan.dev/img/Xrn0Id68_400x400.jpg"}]],"error":null,"digest":"$undefined"}
15:"$10:metadata"
